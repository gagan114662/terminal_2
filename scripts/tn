#!/usr/bin/env python3
"""
TermNet CLI - Autonomous Code Change Interface

A command-line interface for TermNet's autonomous code generation and modification capabilities.
Provides safe, controlled access to AI-powered development tools.
"""

import argparse
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any

# Add the parent directory to sys.path to import termnet modules
sys.path.insert(0, str(Path(__file__).parent.parent))

from termnet.autopilot import Autopilot, AutopilotConfig
from termnet.code_indexer import CodeIndexer
from termnet.planner import WorkPlanner
from termnet.repo_ops import RepoOperations


def setup_logging(verbose: bool = False):
    """Setup logging configuration."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.StreamHandler(sys.stdout),
            logging.FileHandler("termnet.log"),
        ],
    )


def find_repo_root(start_path: Path = None) -> Path | None:
    """Find the repository root by looking for .git directory."""
    if start_path is None:
        start_path = Path.cwd()

    current = start_path.resolve()
    for path in [current] + list(current.parents):
        if (path / ".git").exists():
            return path
    return None


def load_config(repo_path: Path) -> dict[str, Any]:
    """Load TermNet configuration from repository."""
    config_file = repo_path / ".termnet.json"

    # Default configuration
    default_config = {
        "max_tasks_per_run": 5,
        "require_tests": True,
        "auto_push": False,
        "auto_create_pr": False,
        "safety_checks": True,
        "backup_enabled": True,
        "dry_run": False,
        "base_branch": "main",
        "allowed_paths": ["**/*.py", "**/*.js", "**/*.ts", "**/*.md"],
        "blocked_paths": [".git/**", "__pycache__/**", "*.pyc", "node_modules/**"],
    }

    if config_file.exists():
        try:
            with open(config_file) as f:
                user_config = json.load(f)
            default_config.update(user_config)
        except Exception as e:
            print(f"Warning: Failed to load config from {config_file}: {e}")

    return default_config


def cmd_plan(args):
    """Plan implementation for a given goal."""
    repo_path = find_repo_root()
    if not repo_path:
        print("Error: Not in a git repository")
        return 1

    config = load_config(repo_path)
    setup_logging(args.verbose)

    print(f"üìã Planning implementation for: {args.goal}")
    print(f"Repository: {repo_path}")

    try:
        # Initialize planner
        planner = WorkPlanner(max_tasks=config["max_tasks_per_run"])

        # Build repository intelligence
        indexer = CodeIndexer()
        repo_intel = indexer.build_index(
            include_globs=config["allowed_paths"], exclude_globs=config["blocked_paths"]
        )

        # Add repository state
        repo_ops = RepoOperations(str(repo_path))
        repo_state = repo_ops.get_repository_state()
        repo_intel.update(repo_state)

        # Create plan
        plan = planner.plan(args.goal, repo_intel)

        # Generate test specifications
        test_specs = planner.test_plan(plan)

        print("\n‚úÖ Plan created successfully!")
        print(f"Plan hash: {plan['plan_hash']}")
        print(f"Total tasks: {plan['total_tasks']}")
        print(f"Estimated complexity: {plan.get('estimated_complexity', 'unknown')}")

        # Display task breakdown
        print("\nüìù Task Breakdown:")
        for task_id, task_data in plan["nodes"].items():
            risk_icon = (
                "üî¥"
                if task_data.get("risk") == "high"
                else "üü°"
                if task_data.get("risk") == "medium"
                else "üü¢"
            )
            print(
                f"  {risk_icon} {task_id}: {task_data.get('description', 'No description')}"
            )

        # Display test plan
        if test_specs:
            print(f"\nüß™ Test Specifications ({len(test_specs)} tests):")
            for test in test_specs[:3]:  # Show first 3 tests
                print(f"  ‚Ä¢ {test.name}: {test.description}")
            if len(test_specs) > 3:
                print(f"  ... and {len(test_specs) - 3} more tests")

        # Save plan if requested
        if args.output:
            output_path = Path(args.output)
            plan_data = {
                "goal": args.goal,
                "plan": plan,
                "test_specs": [
                    {"name": t.name, "description": t.description, "type": t.type}
                    for t in test_specs
                ],
                "created_at": datetime.now().isoformat(),
            }

            with open(output_path, "w") as f:
                json.dump(plan_data, f, indent=2)
            print(f"\nüíæ Plan saved to: {output_path}")

        return 0

    except Exception as e:
        print(f"‚ùå Planning failed: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def cmd_execute(args):
    """Execute autonomous code changes."""
    repo_path = find_repo_root()
    if not repo_path:
        print("Error: Not in a git repository")
        return 1

    config = load_config(repo_path)
    setup_logging(args.verbose)

    print(f"üöÄ Executing autonomous implementation: {args.goal}")
    print(f"Repository: {repo_path}")

    # Override config with command-line arguments
    if args.dry_run:
        config["dry_run"] = True
    if args.no_safety:
        config["safety_checks"] = False
    if args.auto_push:
        config["auto_push"] = True
    if args.auto_pr:
        config["auto_create_pr"] = True

    print(
        f"Configuration: dry_run={config['dry_run']}, safety_checks={config['safety_checks']}"
    )

    try:
        # Create autopilot configuration
        autopilot_config = AutopilotConfig(
            repo_path=str(repo_path),
            max_tasks_per_run=config["max_tasks_per_run"],
            require_tests=config["require_tests"],
            auto_push=config["auto_push"],
            auto_create_pr=config["auto_create_pr"],
            safety_checks=config["safety_checks"],
            backup_enabled=config["backup_enabled"],
            dry_run=config["dry_run"],
            base_branch=config["base_branch"],
        )

        # Initialize and run autopilot
        autopilot = Autopilot(autopilot_config)

        # Add context if provided
        context = {}
        if args.context:
            for item in args.context:
                key, value = item.split("=", 1)
                context[key] = value

        result = autopilot.execute_goal(args.goal, context)

        # Display results
        if result.success:
            print("\n‚úÖ Execution completed successfully!")
            print(f"Tasks completed: {result.tasks_completed}")
            print(f"Execution time: {result.execution_time:.2f}s")

            if result.branch_created:
                print(f"Branch: {result.branch_created}")
            if result.commit_sha:
                print(f"Commit: {result.commit_sha}")
            if result.pr_url:
                print(f"Pull Request: {result.pr_url}")
        else:
            print(f"\n‚ùå Execution failed: {result.message}")
            if result.errors:
                print("Errors:")
                for error in result.errors:
                    print(f"  ‚Ä¢ {error}")
            if result.warnings:
                print("Warnings:")
                for warning in result.warnings:
                    print(f"  ‚Ä¢ {warning}")

        # Save execution report if requested
        if args.output:
            output_path = Path(args.output)
            report_data = {
                "goal": args.goal,
                "result": {
                    "success": result.success,
                    "message": result.message,
                    "tasks_completed": result.tasks_completed,
                    "tasks_failed": result.tasks_failed,
                    "execution_time": result.execution_time,
                    "branch_created": result.branch_created,
                    "commit_sha": result.commit_sha,
                    "pr_url": result.pr_url,
                    "errors": result.errors,
                    "warnings": result.warnings,
                },
                "config": config,
                "executed_at": datetime.now().isoformat(),
            }

            with open(output_path, "w") as f:
                json.dump(report_data, f, indent=2)
            print(f"\nüíæ Execution report saved to: {output_path}")

        return 0 if result.success else 1

    except Exception as e:
        print(f"‚ùå Execution failed: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def cmd_status(args):
    """Show repository and TermNet status."""
    repo_path = find_repo_root()
    if not repo_path:
        print("Error: Not in a git repository")
        return 1

    config = load_config(repo_path)
    setup_logging(args.verbose)

    print("üìä TermNet Status")
    print(f"Repository: {repo_path}")

    try:
        # Initialize components
        repo_ops = RepoOperations(str(repo_path))
        autopilot_config = AutopilotConfig(repo_path=str(repo_path))
        autopilot = Autopilot(autopilot_config)

        # Get repository state
        repo_state = repo_ops.get_repository_state()
        autopilot_status = autopilot.get_execution_status()

        print("\nüîß Repository State:")
        print(f"  Current branch: {repo_state['current_branch']}")
        print(f"  Current SHA: {repo_state['current_sha']}")
        print(f"  Clean: {'‚úÖ' if repo_state['is_clean'] else '‚ùå'}")

        if repo_state["changed_files"]:
            print(f"  Changed files ({len(repo_state['changed_files'])}):")
            for file_path in repo_state["changed_files"][:5]:
                print(f"    ‚Ä¢ {file_path}")
            if len(repo_state["changed_files"]) > 5:
                print(f"    ... and {len(repo_state['changed_files']) - 5} more")

        print("\n‚öôÔ∏è Configuration:")
        print(f"  Safety checks: {'‚úÖ' if config['safety_checks'] else '‚ùå'}")
        print(f"  Dry run: {'‚úÖ' if config['dry_run'] else '‚ùå'}")
        print(f"  Max tasks: {config['max_tasks_per_run']}")
        print(f"  Base branch: {config['base_branch']}")

        # Build and show index stats
        indexer = CodeIndexer()
        repo_intel = indexer.build_index(
            include_globs=config["allowed_paths"], exclude_globs=config["blocked_paths"]
        )

        print("\nüìÇ Code Index:")
        print(f"  Files indexed: {len(repo_intel.get('files', []))}")
        print(f"  Symbols found: {len(repo_intel.get('symbols', {}))}")

        return 0

    except Exception as e:
        print(f"‚ùå Status check failed: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def cmd_config(args):
    """Manage TermNet configuration."""
    repo_path = find_repo_root()
    if not repo_path:
        print("Error: Not in a git repository")
        return 1

    config_file = repo_path / ".termnet.json"

    if args.action == "show":
        config = load_config(repo_path)
        print("üìã TermNet Configuration:")
        print(json.dumps(config, indent=2))
        return 0

    elif args.action == "init":
        if config_file.exists() and not args.force:
            print(f"Configuration file already exists: {config_file}")
            print("Use --force to overwrite")
            return 1

        # Create default configuration
        default_config = {
            "max_tasks_per_run": 5,
            "require_tests": True,
            "auto_push": False,
            "auto_create_pr": False,
            "safety_checks": True,
            "backup_enabled": True,
            "dry_run": True,
            "base_branch": "main",
            "allowed_paths": ["**/*.py", "**/*.js", "**/*.ts", "**/*.md"],
            "blocked_paths": [".git/**", "__pycache__/**", "*.pyc", "node_modules/**"],
        }

        with open(config_file, "w") as f:
            json.dump(default_config, f, indent=2)

        print(f"‚úÖ Created configuration file: {config_file}")
        return 0

    elif args.action == "set":
        if not args.key or args.value is None:
            print("Error: Both --key and --value are required for 'set' action")
            return 1

        config = load_config(repo_path)

        # Parse value (handle booleans and numbers)
        value = args.value
        if value.lower() in ("true", "false"):
            value = value.lower() == "true"
        elif value.isdigit():
            value = int(value)

        config[args.key] = value

        with open(config_file, "w") as f:
            json.dump(config, f, indent=2)

        print(f"‚úÖ Set {args.key} = {value}")
        return 0

    else:
        print(f"Unknown config action: {args.action}")
        return 1


def main():
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        prog="tn", description="TermNet - Autonomous Code Change Interface"
    )

    parser.add_argument("--version", action="version", version="TermNet 1.0.0")

    parser.add_argument(
        "-v", "--verbose", action="store_true", help="Enable verbose logging"
    )

    subparsers = parser.add_subparsers(dest="command", help="Available commands")

    # Plan command
    plan_parser = subparsers.add_parser(
        "plan", help="Create an implementation plan for a goal"
    )
    plan_parser.add_argument("goal", help="Description of what to implement")
    plan_parser.add_argument("-o", "--output", help="Save plan to file")
    plan_parser.set_defaults(func=cmd_plan)

    # Execute command
    execute_parser = subparsers.add_parser(
        "execute", help="Execute autonomous code changes"
    )
    execute_parser.add_argument("goal", help="Description of what to implement")
    execute_parser.add_argument(
        "--dry-run", action="store_true", help="Perform dry run without making changes"
    )
    execute_parser.add_argument(
        "--no-safety", action="store_true", help="Disable safety checks (dangerous)"
    )
    execute_parser.add_argument(
        "--auto-push", action="store_true", help="Automatically push changes to remote"
    )
    execute_parser.add_argument(
        "--auto-pr", action="store_true", help="Automatically create pull request"
    )
    execute_parser.add_argument(
        "--context", action="append", help="Additional context (key=value pairs)"
    )
    execute_parser.add_argument("-o", "--output", help="Save execution report to file")
    execute_parser.set_defaults(func=cmd_execute)

    # Status command
    status_parser = subparsers.add_parser(
        "status", help="Show repository and TermNet status"
    )
    status_parser.set_defaults(func=cmd_status)

    # Config command
    config_parser = subparsers.add_parser("config", help="Manage TermNet configuration")
    config_parser.add_argument(
        "action", choices=["show", "init", "set"], help="Configuration action"
    )
    config_parser.add_argument("--key", help="Configuration key (for set action)")
    config_parser.add_argument("--value", help="Configuration value (for set action)")
    config_parser.add_argument(
        "--force", action="store_true", help="Force overwrite existing configuration"
    )
    config_parser.set_defaults(func=cmd_config)

    # Parse arguments and execute
    args = parser.parse_args()

    if not hasattr(args, "func"):
        parser.print_help()
        return 1

    try:
        return args.func(args)
    except KeyboardInterrupt:
        print("\n‚ö° Interrupted by user")
        return 130
    except Exception as e:
        print(f"‚ùå Unexpected error: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
